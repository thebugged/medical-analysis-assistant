{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import splitfolders\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 0 files [00:00, ? files/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 4200 files [00:02, 1440.53 files/s]\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into train, test, and validation sets\n",
    "tb_dir = \"data/TB_Chest_Radiography_Database\"\n",
    "splitfolders.ratio(tb_dir, output=\"data/Split_TB_Data\", seed=120, ratio=(0.7, 0.15, 0.15), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "split_tb_dir = \"data/Split_TB_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3797 images belonging to 2 classes.\n",
      "Found 1159 images belonging to 2 classes.\n",
      "Found 1166 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    \"data/Split_TB_Data/train\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    \"data/Split_TB_Data/test\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    \"data/Split_TB_Data/val\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "# normalizer = keras.layers.Rescaling(scale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 19:17:53.230776: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-01-26 19:17:53.230808: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-26 19:17:53.230821: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-26 19:17:53.231132: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-26 19:17:53.231545: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "dense_net = keras.applications.DenseNet169(weights='imagenet', \n",
    "                                           input_shape=(IMG_SIZE, IMG_SIZE, 3), \n",
    "                                           include_top=False)\n",
    "\n",
    "for layer in dense_net.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet169 (Functional)    (None, 7, 7, 1664)        12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 81536)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               20873472  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33516866 (127.86 MB)\n",
      "Trainable params: 20873986 (79.63 MB)\n",
      "Non-trainable params: 12642880 (48.23 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    # normalizer,\n",
    "    dense_net,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "mc = keras.callbacks.ModelCheckpoint('models/tb.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 19:18:01.267049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - ETA: 0s - loss: 4.6119 - accuracy: 0.9376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 67s 245ms/step - loss: 4.6119 - accuracy: 0.9376 - val_loss: 0.8669 - val_accuracy: 0.9794\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 49s 205ms/step - loss: 2.0971 - accuracy: 0.9687 - val_loss: 1.5754 - val_accuracy: 0.9666\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 50s 209ms/step - loss: 1.6127 - accuracy: 0.9750 - val_loss: 0.1677 - val_accuracy: 0.9923\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 49s 206ms/step - loss: 1.2034 - accuracy: 0.9760 - val_loss: 0.3036 - val_accuracy: 0.9906\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 51s 215ms/step - loss: 1.2126 - accuracy: 0.9779 - val_loss: 0.2339 - val_accuracy: 0.9906\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs=10, \n",
    "                    validation_data=val_generator, \n",
    "                    callbacks=[early_stopping, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 15s 208ms/step - loss: 0.5133 - accuracy: 0.9896\n",
      "Test Accuracy: 98.96%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qt/hcj8mn3s4rq62dxlffdwnnzw0000gn/T/tmpv2fdrv0w/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qt/hcj8mn3s4rq62dxlffdwnnzw0000gn/T/tmpv2fdrv0w/assets\n",
      "2024-01-26 19:23:11.202575: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-26 19:23:11.202597: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-26 19:23:11.203727: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/qt/hcj8mn3s4rq62dxlffdwnnzw0000gn/T/tmpv2fdrv0w\n",
      "2024-01-26 19:23:11.251252: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-26 19:23:11.251270: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/qt/hcj8mn3s4rq62dxlffdwnnzw0000gn/T/tmpv2fdrv0w\n",
      "2024-01-26 19:23:11.344513: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-26 19:23:11.389400: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-26 19:23:12.523991: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/qt/hcj8mn3s4rq62dxlffdwnnzw0000gn/T/tmpv2fdrv0w\n",
      "2024-01-26 19:23:12.892112: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 1688382 microseconds.\n",
      "2024-01-26 19:23:13.308036: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 265, Total Ops 869, % non-converted = 30.49 %\n",
      " * 265 ARITH ops\n",
      "\n",
      "- arith.constant:  265 occurrences  (f32: 262, i32: 3)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 86)\n",
      "  (f32: 3)\n",
      "  (f32: 82)\n",
      "  (f32: 168)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 86)\n",
      "  (f32: 2)\n",
      "  (uq_8: 169)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TFLite model\n",
    "with open('models/tb_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 21s 236ms/step - loss: 0.5776 - accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5776378512382507, 0.9861949682235718]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model and evaluate on the test set\n",
    "tb_model = keras.models.load_model(\"models/tb.h5\")\n",
    "tb_model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
